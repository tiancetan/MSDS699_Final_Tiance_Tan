{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Final Project - Heart Disease\n---\n\nTiance Tan\n\n03/08/2021\n",
      "metadata": {
        "tags": [],
        "cell_id": "00000-d8d8ed42-f5cd-4063-b645-a274fb60b3c2",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Abstract**\n\nStatistical learning models were applied to Heart Disease data in order to analyze the presense of heart disease based on some differenct facets. In this analysis, we consider both multinomial response and binary response for the model and perform cross validation on them. Ultimately the predictive power of the models appears to be effective but a little bit limited by the available data. Additional data collection is recommended.",
      "metadata": {
        "tags": [],
        "cell_id": "00001-0debcd70-58de-4601-8b04-618057854e35",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Introduction**\n\nHeart disease is a form of heart disease and blood vessel disease. Heart ailments are the leading reason of dying globally. Some danger factors for heart illnesses encompass smoking, high blood pressure and so on. Analyzing datasets associated to heart ailment can assist scientific specialists comprehend about what contributes extra to the patient’s seriousness of disease, for that reason suitable treatment can be utilized earlier.",
      "metadata": {
        "tags": [],
        "cell_id": "00001-5e9514af-cafc-4237-95cb-c11a68fd5a76",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Research Question / Hypothesis **\n\n\n**Research Question:** \n\n- Can we use patients' demographics information to predict their heart disease level? \n\n- What contributes extra to the patient’s seriousness of disease?\n\n- How accurate is the prediction?\n\n**Hypothesis:**\n\n- It is possible to make the prediction. However, the dateset is not large enough, the results might not be applicable for all heart-disease patients.",
      "metadata": {
        "tags": [],
        "cell_id": "00003-db3126a3-e41d-4249-b81d-0ac503b36744",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "__Load Data__",
      "metadata": {
        "tags": [],
        "cell_id": "00004-982b2d03-b212-41d8-9596-3d9e5191d824",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00005-ef3ec1bc-211d-43f3-b2b7-a8fdd66a91b0",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1f0d6bf9",
        "execution_millis": 1175,
        "execution_start": 1615513684212,
        "deepnote_cell_type": "code"
      },
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model    import *\nfrom sklearn.metrics         import mean_squared_error\nfrom sklearn.pipeline        import Pipeline\nfrom sklearn.preprocessing   import StandardScaler\nfrom sklearn.metrics         import accuracy_score\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn.metrics         import classification_report\nfrom sklearn                 import neighbors\nfrom sklearn.preprocessing   import *\nfrom sklearn.neighbors       import KNeighborsClassifier\nfrom sklearn.svm             import SVC\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.decomposition   import PCA\nfrom sklearn.preprocessing   import StandardScaler\nfrom sklearn.pipeline        import Pipeline\nfrom sklearn.tree            import DecisionTreeClassifier\nfrom sklearn.base            import BaseEstimator\nfrom sklearn.ensemble        import ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.linear_model    import LogisticRegression, RidgeClassifier\nfrom sklearn.metrics         import f1_score\nfrom sklearn.naive_bayes     import GaussianNB\nfrom sklearn.compose         import ColumnTransformer\nfrom math                    import sqrt",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-138a818b-b723-4b07-b905-155d85b52caa",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b7a367ae",
        "execution_millis": 2,
        "execution_start": 1615513685389,
        "deepnote_cell_type": "code"
      },
      "source": "# # Visualize pipeline\n# # This is good idea for your Final Project\n\n# from sklearn import set_config\n\n# set_config(display='diagram')\n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-48e17a65-5f90-4cff-b355-b54250836577",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "630830e0",
        "execution_millis": 6,
        "execution_start": 1615513685396,
        "deepnote_cell_type": "code"
      },
      "source": "heart = pd.read_csv(\"heart.csv\") ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00007-f3fd1dba-e42e-4017-8a57-b9671a580ea4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3e291eae",
        "execution_millis": 10,
        "execution_start": 1615513685413,
        "deepnote_cell_type": "code"
      },
      "source": "heart.target.value_counts()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "1    165\n0    138\nName: target, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-d207d80a-7dcc-45aa-baef-58be7357a8c4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d5c13df7",
        "execution_millis": 33,
        "execution_start": 1615513685435,
        "deepnote_cell_type": "code"
      },
      "source": "heart.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "application/vnd.deepnote.dataframe.v2+json": {
              "row_count": 5,
              "column_count": 14,
              "columns": [
                {
                  "name": "age",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "min": 37,
                    "max": 63,
                    "histogram": [
                      {
                        "bin_start": 37,
                        "bin_end": 39.6,
                        "count": 1
                      },
                      {
                        "bin_start": 39.6,
                        "bin_end": 42.2,
                        "count": 1
                      },
                      {
                        "bin_start": 42.2,
                        "bin_end": 44.8,
                        "count": 0
                      },
                      {
                        "bin_start": 44.8,
                        "bin_end": 47.4,
                        "count": 0
                      },
                      {
                        "bin_start": 47.4,
                        "bin_end": 50,
                        "count": 0
                      },
                      {
                        "bin_start": 50,
                        "bin_end": 52.6,
                        "count": 0
                      },
                      {
                        "bin_start": 52.6,
                        "bin_end": 55.2,
                        "count": 0
                      },
                      {
                        "bin_start": 55.2,
                        "bin_end": 57.8,
                        "count": 2
                      },
                      {
                        "bin_start": 57.8,
                        "bin_end": 60.400000000000006,
                        "count": 0
                      },
                      {
                        "bin_start": 60.400000000000006,
                        "bin_end": 63,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "sex",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0,
                    "max": 1,
                    "histogram": [
                      {
                        "bin_start": 0,
                        "bin_end": 0.1,
                        "count": 2
                      },
                      {
                        "bin_start": 0.1,
                        "bin_end": 0.2,
                        "count": 0
                      },
                      {
                        "bin_start": 0.2,
                        "bin_end": 0.30000000000000004,
                        "count": 0
                      },
                      {
                        "bin_start": 0.30000000000000004,
                        "bin_end": 0.4,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4,
                        "bin_end": 0.5,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5,
                        "bin_end": 0.6000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6000000000000001,
                        "bin_end": 0.7000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7000000000000001,
                        "bin_end": 0.8,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8,
                        "bin_end": 0.9,
                        "count": 0
                      },
                      {
                        "bin_start": 0.9,
                        "bin_end": 1,
                        "count": 3
                      }
                    ]
                  }
                },
                {
                  "name": "cp",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 4,
                    "nan_count": 0,
                    "min": 0,
                    "max": 3,
                    "histogram": [
                      {
                        "bin_start": 0,
                        "bin_end": 0.3,
                        "count": 1
                      },
                      {
                        "bin_start": 0.3,
                        "bin_end": 0.6,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6,
                        "bin_end": 0.8999999999999999,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8999999999999999,
                        "bin_end": 1.2,
                        "count": 2
                      },
                      {
                        "bin_start": 1.2,
                        "bin_end": 1.5,
                        "count": 0
                      },
                      {
                        "bin_start": 1.5,
                        "bin_end": 1.7999999999999998,
                        "count": 0
                      },
                      {
                        "bin_start": 1.7999999999999998,
                        "bin_end": 2.1,
                        "count": 1
                      },
                      {
                        "bin_start": 2.1,
                        "bin_end": 2.4,
                        "count": 0
                      },
                      {
                        "bin_start": 2.4,
                        "bin_end": 2.6999999999999997,
                        "count": 0
                      },
                      {
                        "bin_start": 2.6999999999999997,
                        "bin_end": 3,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "trestbps",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 3,
                    "nan_count": 0,
                    "min": 120,
                    "max": 145,
                    "histogram": [
                      {
                        "bin_start": 120,
                        "bin_end": 122.5,
                        "count": 2
                      },
                      {
                        "bin_start": 122.5,
                        "bin_end": 125,
                        "count": 0
                      },
                      {
                        "bin_start": 125,
                        "bin_end": 127.5,
                        "count": 0
                      },
                      {
                        "bin_start": 127.5,
                        "bin_end": 130,
                        "count": 0
                      },
                      {
                        "bin_start": 130,
                        "bin_end": 132.5,
                        "count": 2
                      },
                      {
                        "bin_start": 132.5,
                        "bin_end": 135,
                        "count": 0
                      },
                      {
                        "bin_start": 135,
                        "bin_end": 137.5,
                        "count": 0
                      },
                      {
                        "bin_start": 137.5,
                        "bin_end": 140,
                        "count": 0
                      },
                      {
                        "bin_start": 140,
                        "bin_end": 142.5,
                        "count": 0
                      },
                      {
                        "bin_start": 142.5,
                        "bin_end": 145,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "chol",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "min": 204,
                    "max": 354,
                    "histogram": [
                      {
                        "bin_start": 204,
                        "bin_end": 219,
                        "count": 1
                      },
                      {
                        "bin_start": 219,
                        "bin_end": 234,
                        "count": 1
                      },
                      {
                        "bin_start": 234,
                        "bin_end": 249,
                        "count": 1
                      },
                      {
                        "bin_start": 249,
                        "bin_end": 264,
                        "count": 1
                      },
                      {
                        "bin_start": 264,
                        "bin_end": 279,
                        "count": 0
                      },
                      {
                        "bin_start": 279,
                        "bin_end": 294,
                        "count": 0
                      },
                      {
                        "bin_start": 294,
                        "bin_end": 309,
                        "count": 0
                      },
                      {
                        "bin_start": 309,
                        "bin_end": 324,
                        "count": 0
                      },
                      {
                        "bin_start": 324,
                        "bin_end": 339,
                        "count": 0
                      },
                      {
                        "bin_start": 339,
                        "bin_end": 354,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "fbs",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0,
                    "max": 1,
                    "histogram": [
                      {
                        "bin_start": 0,
                        "bin_end": 0.1,
                        "count": 4
                      },
                      {
                        "bin_start": 0.1,
                        "bin_end": 0.2,
                        "count": 0
                      },
                      {
                        "bin_start": 0.2,
                        "bin_end": 0.30000000000000004,
                        "count": 0
                      },
                      {
                        "bin_start": 0.30000000000000004,
                        "bin_end": 0.4,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4,
                        "bin_end": 0.5,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5,
                        "bin_end": 0.6000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6000000000000001,
                        "bin_end": 0.7000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7000000000000001,
                        "bin_end": 0.8,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8,
                        "bin_end": 0.9,
                        "count": 0
                      },
                      {
                        "bin_start": 0.9,
                        "bin_end": 1,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "restecg",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0,
                    "max": 1,
                    "histogram": [
                      {
                        "bin_start": 0,
                        "bin_end": 0.1,
                        "count": 2
                      },
                      {
                        "bin_start": 0.1,
                        "bin_end": 0.2,
                        "count": 0
                      },
                      {
                        "bin_start": 0.2,
                        "bin_end": 0.30000000000000004,
                        "count": 0
                      },
                      {
                        "bin_start": 0.30000000000000004,
                        "bin_end": 0.4,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4,
                        "bin_end": 0.5,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5,
                        "bin_end": 0.6000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6000000000000001,
                        "bin_end": 0.7000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7000000000000001,
                        "bin_end": 0.8,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8,
                        "bin_end": 0.9,
                        "count": 0
                      },
                      {
                        "bin_start": 0.9,
                        "bin_end": 1,
                        "count": 3
                      }
                    ]
                  }
                },
                {
                  "name": "thalach",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "min": 150,
                    "max": 187,
                    "histogram": [
                      {
                        "bin_start": 150,
                        "bin_end": 153.7,
                        "count": 1
                      },
                      {
                        "bin_start": 153.7,
                        "bin_end": 157.4,
                        "count": 0
                      },
                      {
                        "bin_start": 157.4,
                        "bin_end": 161.1,
                        "count": 0
                      },
                      {
                        "bin_start": 161.1,
                        "bin_end": 164.8,
                        "count": 1
                      },
                      {
                        "bin_start": 164.8,
                        "bin_end": 168.5,
                        "count": 0
                      },
                      {
                        "bin_start": 168.5,
                        "bin_end": 172.2,
                        "count": 1
                      },
                      {
                        "bin_start": 172.2,
                        "bin_end": 175.9,
                        "count": 0
                      },
                      {
                        "bin_start": 175.9,
                        "bin_end": 179.6,
                        "count": 1
                      },
                      {
                        "bin_start": 179.6,
                        "bin_end": 183.3,
                        "count": 0
                      },
                      {
                        "bin_start": 183.3,
                        "bin_end": 187,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "exang",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0,
                    "max": 1,
                    "histogram": [
                      {
                        "bin_start": 0,
                        "bin_end": 0.1,
                        "count": 4
                      },
                      {
                        "bin_start": 0.1,
                        "bin_end": 0.2,
                        "count": 0
                      },
                      {
                        "bin_start": 0.2,
                        "bin_end": 0.30000000000000004,
                        "count": 0
                      },
                      {
                        "bin_start": 0.30000000000000004,
                        "bin_end": 0.4,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4,
                        "bin_end": 0.5,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5,
                        "bin_end": 0.6000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6000000000000001,
                        "bin_end": 0.7000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7000000000000001,
                        "bin_end": 0.8,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8,
                        "bin_end": 0.9,
                        "count": 0
                      },
                      {
                        "bin_start": 0.9,
                        "bin_end": 1,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "oldpeak",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "min": 0.6,
                    "max": 3.5,
                    "histogram": [
                      {
                        "bin_start": 0.6,
                        "bin_end": 0.8899999999999999,
                        "count": 2
                      },
                      {
                        "bin_start": 0.8899999999999999,
                        "bin_end": 1.18,
                        "count": 0
                      },
                      {
                        "bin_start": 1.18,
                        "bin_end": 1.4699999999999998,
                        "count": 1
                      },
                      {
                        "bin_start": 1.4699999999999998,
                        "bin_end": 1.7599999999999998,
                        "count": 0
                      },
                      {
                        "bin_start": 1.7599999999999998,
                        "bin_end": 2.05,
                        "count": 0
                      },
                      {
                        "bin_start": 2.05,
                        "bin_end": 2.34,
                        "count": 1
                      },
                      {
                        "bin_start": 2.34,
                        "bin_end": 2.63,
                        "count": 0
                      },
                      {
                        "bin_start": 2.63,
                        "bin_end": 2.92,
                        "count": 0
                      },
                      {
                        "bin_start": 2.92,
                        "bin_end": 3.21,
                        "count": 0
                      },
                      {
                        "bin_start": 3.21,
                        "bin_end": 3.5,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "slope",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0,
                    "max": 2,
                    "histogram": [
                      {
                        "bin_start": 0,
                        "bin_end": 0.2,
                        "count": 2
                      },
                      {
                        "bin_start": 0.2,
                        "bin_end": 0.4,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4,
                        "bin_end": 0.6000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6000000000000001,
                        "bin_end": 0.8,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8,
                        "bin_end": 1,
                        "count": 0
                      },
                      {
                        "bin_start": 1,
                        "bin_end": 1.2000000000000002,
                        "count": 0
                      },
                      {
                        "bin_start": 1.2000000000000002,
                        "bin_end": 1.4000000000000001,
                        "count": 0
                      },
                      {
                        "bin_start": 1.4000000000000001,
                        "bin_end": 1.6,
                        "count": 0
                      },
                      {
                        "bin_start": 1.6,
                        "bin_end": 1.8,
                        "count": 0
                      },
                      {
                        "bin_start": 1.8,
                        "bin_end": 2,
                        "count": 3
                      }
                    ]
                  }
                },
                {
                  "name": "ca",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": 0,
                    "max": 0,
                    "histogram": [
                      {
                        "bin_start": -0.5,
                        "bin_end": -0.4,
                        "count": 0
                      },
                      {
                        "bin_start": -0.4,
                        "bin_end": -0.3,
                        "count": 0
                      },
                      {
                        "bin_start": -0.3,
                        "bin_end": -0.19999999999999996,
                        "count": 0
                      },
                      {
                        "bin_start": -0.19999999999999996,
                        "bin_end": -0.09999999999999998,
                        "count": 0
                      },
                      {
                        "bin_start": -0.09999999999999998,
                        "bin_end": 0,
                        "count": 0
                      },
                      {
                        "bin_start": 0,
                        "bin_end": 0.10000000000000009,
                        "count": 5
                      },
                      {
                        "bin_start": 0.10000000000000009,
                        "bin_end": 0.20000000000000007,
                        "count": 0
                      },
                      {
                        "bin_start": 0.20000000000000007,
                        "bin_end": 0.30000000000000004,
                        "count": 0
                      },
                      {
                        "bin_start": 0.30000000000000004,
                        "bin_end": 0.4,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4,
                        "bin_end": 0.5,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "thal",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 1,
                    "max": 2,
                    "histogram": [
                      {
                        "bin_start": 1,
                        "bin_end": 1.1,
                        "count": 1
                      },
                      {
                        "bin_start": 1.1,
                        "bin_end": 1.2,
                        "count": 0
                      },
                      {
                        "bin_start": 1.2,
                        "bin_end": 1.3,
                        "count": 0
                      },
                      {
                        "bin_start": 1.3,
                        "bin_end": 1.4,
                        "count": 0
                      },
                      {
                        "bin_start": 1.4,
                        "bin_end": 1.5,
                        "count": 0
                      },
                      {
                        "bin_start": 1.5,
                        "bin_end": 1.6,
                        "count": 0
                      },
                      {
                        "bin_start": 1.6,
                        "bin_end": 1.7000000000000002,
                        "count": 0
                      },
                      {
                        "bin_start": 1.7000000000000002,
                        "bin_end": 1.8,
                        "count": 0
                      },
                      {
                        "bin_start": 1.8,
                        "bin_end": 1.9,
                        "count": 0
                      },
                      {
                        "bin_start": 1.9,
                        "bin_end": 2,
                        "count": 4
                      }
                    ]
                  }
                },
                {
                  "name": "target",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 1,
                    "nan_count": 0,
                    "min": 1,
                    "max": 1,
                    "histogram": [
                      {
                        "bin_start": 0.5,
                        "bin_end": 0.6,
                        "count": 0
                      },
                      {
                        "bin_start": 0.6,
                        "bin_end": 0.7,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7,
                        "bin_end": 0.8,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8,
                        "bin_end": 0.9,
                        "count": 0
                      },
                      {
                        "bin_start": 0.9,
                        "bin_end": 1,
                        "count": 0
                      },
                      {
                        "bin_start": 1,
                        "bin_end": 1.1,
                        "count": 5
                      },
                      {
                        "bin_start": 1.1,
                        "bin_end": 1.2000000000000002,
                        "count": 0
                      },
                      {
                        "bin_start": 1.2000000000000002,
                        "bin_end": 1.3,
                        "count": 0
                      },
                      {
                        "bin_start": 1.3,
                        "bin_end": 1.4,
                        "count": 0
                      },
                      {
                        "bin_start": 1.4,
                        "bin_end": 1.5,
                        "count": 0
                      }
                    ]
                  }
                },
                {
                  "name": "_deepnote_index_column",
                  "dtype": "int64"
                }
              ],
              "rows_top": [
                {
                  "age": 63,
                  "sex": 1,
                  "cp": 3,
                  "trestbps": 145,
                  "chol": 233,
                  "fbs": 1,
                  "restecg": 0,
                  "thalach": 150,
                  "exang": 0,
                  "oldpeak": 2.3,
                  "slope": 0,
                  "ca": 0,
                  "thal": 1,
                  "target": 1,
                  "_deepnote_index_column": 0
                },
                {
                  "age": 37,
                  "sex": 1,
                  "cp": 2,
                  "trestbps": 130,
                  "chol": 250,
                  "fbs": 0,
                  "restecg": 1,
                  "thalach": 187,
                  "exang": 0,
                  "oldpeak": 3.5,
                  "slope": 0,
                  "ca": 0,
                  "thal": 2,
                  "target": 1,
                  "_deepnote_index_column": 1
                },
                {
                  "age": 41,
                  "sex": 0,
                  "cp": 1,
                  "trestbps": 130,
                  "chol": 204,
                  "fbs": 0,
                  "restecg": 0,
                  "thalach": 172,
                  "exang": 0,
                  "oldpeak": 1.4,
                  "slope": 2,
                  "ca": 0,
                  "thal": 2,
                  "target": 1,
                  "_deepnote_index_column": 2
                },
                {
                  "age": 56,
                  "sex": 1,
                  "cp": 1,
                  "trestbps": 120,
                  "chol": 236,
                  "fbs": 0,
                  "restecg": 1,
                  "thalach": 178,
                  "exang": 0,
                  "oldpeak": 0.8,
                  "slope": 2,
                  "ca": 0,
                  "thal": 2,
                  "target": 1,
                  "_deepnote_index_column": 3
                },
                {
                  "age": 57,
                  "sex": 0,
                  "cp": 0,
                  "trestbps": 120,
                  "chol": 354,
                  "fbs": 0,
                  "restecg": 1,
                  "thalach": 163,
                  "exang": 1,
                  "oldpeak": 0.6,
                  "slope": 2,
                  "ca": 0,
                  "thal": 2,
                  "target": 1,
                  "_deepnote_index_column": 4
                }
              ],
              "rows_bottom": null
            },
            "text/plain": "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n0   63    1   3       145   233    1        0      150      0      2.3      0   \n1   37    1   2       130   250    0        1      187      0      3.5      0   \n2   41    0   1       130   204    0        0      172      0      1.4      2   \n3   56    1   1       120   236    0        1      178      0      0.8      2   \n4   57    0   0       120   354    0        1      163      1      0.6      2   \n\n   ca  thal  target  \n0   0     1       1  \n1   0     2       1  \n2   0     2       1  \n3   0     2       1  \n4   0     2       1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-61d896e6-e5f8-4782-8a59-9a6a701206c6",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "701d2e8b",
        "execution_millis": 11,
        "execution_start": 1615513685502,
        "deepnote_cell_type": "code"
      },
      "source": "heart.isna().any()\n#No missing value",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "age         False\nsex         False\ncp          False\ntrestbps    False\nchol        False\nfbs         False\nrestecg     False\nthalach     False\nexang       False\noldpeak     False\nslope       False\nca          False\nthal        False\ntarget      False\ndtype: bool"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-eabc5855-1984-408d-8003-fdaaeeff2b3c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c36cc427",
        "execution_millis": 12,
        "execution_start": 1615514752093,
        "deepnote_cell_type": "code"
      },
      "source": "#Apply OneHotEncoder on the categorical features and StandardScalar on continuous features\nnumeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\ncategorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n\npreprocessor = ColumnTransformer(\n                (OneHotEncoder(),categorical_features),\n                (StandardScaler(),numeric_features),\n                remainder = 'passthrough')\npipe_pre = Pipeline([('preprocessor', preprocessor)])",
      "execution_count": 21,
      "outputs": [
        {
          "name": "stderr",
          "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass remainder=(StandardScaler(), ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']) as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-25353841-6002-4001-a71d-ef3b02e8534a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "76afaa1f",
        "execution_millis": 1,
        "execution_start": 1615513685504,
        "deepnote_cell_type": "code"
      },
      "source": "X=heart.drop(['target'],axis=1)\ny=heart.target",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-5d238e37-3d1d-4274-bf90-c326038623c4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "165591e0",
        "execution_millis": 32,
        "execution_start": 1615513685509,
        "deepnote_cell_type": "code"
      },
      "source": "ColumnTransformer(X)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "ColumnTransformer(transformers=     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n0     63    1   3       145   233    1        0      150      0      2.3   \n1     37    1   2       130   250    0        1      187      0      3.5   \n2     41    0   1       130   204    0        0      172      0      1.4   \n3     56    1   1       120   236    0        1      178      0      0.8   \n4     57    0   0       120   354    0        1      163      1      0.6   \n..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n298   57    0   0       140   241    0        1      123      1      0.2   \n299   45    1   3       110   264    0        1      132      0      1.2   \n300   68    1   0       144   193    1        1      141      0      3.4   \n301   57    1   0       130   131    0        1      115      1      1.2   \n302   57    0   1       130   236    0        0      174      0      0.0   \n\n     slope  ca  thal  \n0        0   0     1  \n1        0   0     2  \n2        2   0     2  \n3        2   0     2  \n4        2   0     2  \n..     ...  ..   ...  \n298      1   0     3  \n299      1   0     3  \n300      1   2     3  \n301      1   1     3  \n302      1   1     2  \n\n[303 rows x 13 columns])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00011-ee58d73f-68ce-4e9b-a171-c33a65abd6b9",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9f5d89b8",
        "execution_millis": 4,
        "execution_start": 1615513685543,
        "deepnote_cell_type": "code"
      },
      "source": "X_train, X_test, y_train, y_test             = train_test_split(X,       y, random_state=42)\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "__Logistic Regression__",
      "metadata": {
        "tags": [],
        "cell_id": "00015-b85622fc-8965-4a88-bdb0-3b31f92c88ec",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-a8bd4652-0514-4700-b43f-3838abb1d5be",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c3732013",
        "execution_millis": 13618,
        "execution_start": 1615513685556,
        "deepnote_cell_type": "code"
      },
      "source": "#Grid Search with Logistic Regression on the dataset\nC = np.logspace(0, 4, 10)\npenalty = ['l2', 'none']\nclass_weight=['balanced','None']\nsolver = ['newton-cg','lbfgs', 'sag', 'saga']\nhyperparameters = dict(C=C, \n                       penalty=penalty,\n                       class_weight=class_weight,\n                       solver=solver,)\n\nclf_grid = GridSearchCV(LogisticRegression(),\n                        hyperparameters,\n                        cv=5,\n                        verbose=True,\n)\nclf_grid.fit(X_train, y_train);",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00017-efac5210-ac91-4ce8-a290-1dfb0996fe3e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b6f5b91",
        "execution_millis": 12,
        "execution_start": 1615513699175,
        "deepnote_cell_type": "code"
      },
      "source": "#Get parameters from the best estimator\nclf_grid.best_estimator_.get_params()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "{'C': 1.0,\n 'class_weight': 'None',\n 'dual': False,\n 'fit_intercept': True,\n 'intercept_scaling': 1,\n 'l1_ratio': None,\n 'max_iter': 100,\n 'multi_class': 'auto',\n 'n_jobs': None,\n 'penalty': 'l2',\n 'random_state': None,\n 'solver': 'newton-cg',\n 'tol': 0.0001,\n 'verbose': 0,\n 'warm_start': False}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00017-1c2a4fc5-3618-4e8f-a021-0c99dab4d6ac",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "85299137",
        "execution_millis": 10,
        "execution_start": 1615513699183,
        "deepnote_cell_type": "code"
      },
      "source": "#Fit on the training data and predict on the validation data.\npipe = Pipeline([('scaler',       StandardScaler()), \n                 ('logistic',     clf_grid.best_estimator_)])\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_validation)\nacc1 = accuracy_score(y_validation, y_pred)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00017-20f3f62d-0e84-4045-a832-2ac6e17b91a4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b623e53d",
        "execution_millis": 0,
        "execution_start": 1615513699239,
        "deepnote_cell_type": "code"
      },
      "source": "",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "__ExtraTreesClassifier__\n\n__RandomForestClassifier__\n\n__SVC__\n\n__KNN__",
      "metadata": {
        "tags": [],
        "cell_id": "00025-76c19206-4733-4d5a-b2f9-b10a3cc34abb",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-3d48c060-42cf-4f34-8079-9cc11930480c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b3f5334f",
        "execution_millis": 0,
        "execution_start": 1615513699240,
        "deepnote_cell_type": "code"
      },
      "source": "# Automated cross validation search across algorithms and hyperparameters\n\nclass DummyEstimator(BaseEstimator):\n    \"Pass through class, methods are present but do nothing.\"\n    def fit(self): pass\n    def score(self): pass\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('clf', DummyEstimator())\n])\n\nsearch_space = [\n    \n    {\n        'clf': [ExtraTreesClassifier()],\n        'clf__criterion': ['gini', 'entropy'],\n        'clf__n_estimators': [50,100,150,200],\n        'clf__max_features': ['auto','sqrt','log2'],\n        'clf__max_depth': [10, 20, 50,100],\n        'clf__class_weight' : ['balanced','balanced_subsample']},\n    {\n        'clf': [RandomForestClassifier()],\n        'clf__n_estimators': range(50, 400, 50),\n        'clf__min_samples_leaf': [1, 2],\n        'clf__max_depth': [10, 20, 30, 50,100]\n    },\n    {\n        'clf': [SVC()],\n        'clf__C': np.logspace(0, 4, 10),\n        'clf__kernel': ['poly', 'rbf', 'sigmoid'],\n        'clf__degree': range(4)\n    },\n    {\n        'clf': [KNeighborsClassifier()],\n        'clf__n_neighbors': [3, 5, 11, 25, 51]}\n]",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-2314cd2d-55cf-4156-85ee-926c4d1d4c96",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a9b2da7",
        "execution_millis": 10504,
        "execution_start": 1615515286275,
        "deepnote_cell_type": "code"
      },
      "source": "#Random Search with Logistic Regression on dataset\nclf_algos_rand = RandomizedSearchCV(estimator=pipe, \n                                    param_distributions=search_space, \n                                    n_iter=25,\n                                    cv=5, \n                                    n_jobs=-1,\n                                    verbose=1,\n                                    scoring='f1_weighted')\nclf_algos_rand.fit(X_train, y_train)\nclf_algos_rand.best_estimator_",
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "text": "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
          "output_type": "stream"
        },
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "Pipeline(steps=[('scaler', StandardScaler()),\n                ('clf',\n                 RandomForestClassifier(max_depth=20, min_samples_leaf=2,\n                                        n_estimators=50))])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-04efb197-8c71-41d6-813f-5e1aecc3bb3e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "78b73ff4",
        "execution_millis": 347,
        "execution_start": 1615515331583,
        "deepnote_cell_type": "code"
      },
      "source": "# Define pipeline with the set of final hyperparameters for all steps.\npipe2 = Pipeline(steps=[('scaler', StandardScaler()),\n                       ('clf',\n                         RandomForestClassifier(max_depth=15, min_samples_leaf=5,\n                                        n_estimators=50))])\n\nf1_test_best = 0\n\nfor run in range(5):\n    # Traing final model on all the avaible training data\n    pipe2.fit(X_train, y_train)\n\n    y_pred = pipe2.predict(X_validation)\n    f1_test = f1_score(y_validation, y_pred, average='weighted')\n\n    # Update champion score\n    if f1_test > f1_test_best:\n        f1_test_best = f1_test",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-c9622376-6c90-45a9-be9e-ae5e41a1a297",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "43cf044d",
        "execution_millis": 8,
        "execution_start": 1615515332017,
        "deepnote_cell_type": "code"
      },
      "source": "print(f\"F1 accuracy - {f1_test_best:,.2f}\")",
      "execution_count": 39,
      "outputs": [
        {
          "name": "stdout",
          "text": "F1 accuracy - 0.81\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-56e79912-a404-4882-9fed-d7278afa06cd",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6829fb43",
        "execution_millis": 54,
        "execution_start": 1615515390202,
        "deepnote_cell_type": "code"
      },
      "source": "#Fit on the training data and predict on the validation data.\npipe2.fit(X_train, y_train)\ny_pred2 = pipe2.predict(X_validation)\nacc2 = accuracy_score(y_validation, y_pred2)",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00029-94cb9fff-ff50-4f8e-a89f-6f40d5889eda",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a088df43",
        "execution_millis": 2,
        "execution_start": 1615515390522,
        "deepnote_cell_type": "code"
      },
      "source": "rmse_res = [sqrt(mean_squared_error(y_validation,y_pred)),sqrt(mean_squared_error(y_validation,y_pred2))]\naccuracy_res = [acc1,acc2]",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00030-62e6edc7-5ea8-495e-b863-3d430e30c8d4",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "65601ff5",
        "execution_millis": 13,
        "execution_start": 1615515390645,
        "deepnote_cell_type": "code"
      },
      "source": "Evaluation_Metric = pd.DataFrame({\"Model\": [\"LogisticRegression\", \"RandomForestClassifier\"],\n                   \"RMSE\": rmse_res,\n                   \"Accuracy\": accuracy_res})\nEvaluation_Metric",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "application/vnd.deepnote.dataframe.v2+json": {
              "row_count": 2,
              "column_count": 3,
              "columns": [
                {
                  "name": "Model",
                  "dtype": "object",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "categories": [
                      {
                        "name": "LogisticRegression",
                        "count": 1
                      },
                      {
                        "name": "RandomForestClassifier",
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "RMSE",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0.39735970711951313,
                    "max": 0.45883146774112354,
                    "histogram": [
                      {
                        "bin_start": 0.39735970711951313,
                        "bin_end": 0.40350688318167416,
                        "count": 1
                      },
                      {
                        "bin_start": 0.40350688318167416,
                        "bin_end": 0.4096540592438352,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4096540592438352,
                        "bin_end": 0.4158012353059963,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4158012353059963,
                        "bin_end": 0.4219484113681573,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4219484113681573,
                        "bin_end": 0.42809558743031834,
                        "count": 0
                      },
                      {
                        "bin_start": 0.42809558743031834,
                        "bin_end": 0.43424276349247937,
                        "count": 0
                      },
                      {
                        "bin_start": 0.43424276349247937,
                        "bin_end": 0.4403899395546404,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4403899395546404,
                        "bin_end": 0.4465371156168015,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4465371156168015,
                        "bin_end": 0.4526842916789625,
                        "count": 0
                      },
                      {
                        "bin_start": 0.4526842916789625,
                        "bin_end": 0.45883146774112354,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "Accuracy",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 2,
                    "nan_count": 0,
                    "min": 0.8245614035087719,
                    "max": 0.8421052631578947,
                    "histogram": [
                      {
                        "bin_start": 0.8245614035087719,
                        "bin_end": 0.8263157894736842,
                        "count": 1
                      },
                      {
                        "bin_start": 0.8263157894736842,
                        "bin_end": 0.8280701754385965,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8280701754385965,
                        "bin_end": 0.8298245614035088,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8298245614035088,
                        "bin_end": 0.8315789473684211,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8315789473684211,
                        "bin_end": 0.8333333333333333,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8333333333333333,
                        "bin_end": 0.8350877192982455,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8350877192982455,
                        "bin_end": 0.8368421052631578,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8368421052631578,
                        "bin_end": 0.8385964912280701,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8385964912280701,
                        "bin_end": 0.8403508771929824,
                        "count": 0
                      },
                      {
                        "bin_start": 0.8403508771929824,
                        "bin_end": 0.8421052631578947,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "_deepnote_index_column",
                  "dtype": "int64"
                }
              ],
              "rows_top": [
                {
                  "Model": "LogisticRegression",
                  "RMSE": 0.45883146774112354,
                  "Accuracy": 0.8245614035087719,
                  "_deepnote_index_column": 0
                },
                {
                  "Model": "RandomForestClassifier",
                  "RMSE": 0.39735970711951313,
                  "Accuracy": 0.8421052631578947,
                  "_deepnote_index_column": 1
                }
              ],
              "rows_bottom": null
            },
            "text/plain": "                    Model      RMSE  Accuracy\n0      LogisticRegression  0.458831  0.824561\n1  RandomForestClassifier  0.397360  0.842105",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LogisticRegression</td>\n      <td>0.458831</td>\n      <td>0.824561</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForestClassifier</td>\n      <td>0.397360</td>\n      <td>0.842105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "__Final evaluation__",
      "metadata": {
        "tags": [],
        "cell_id": "00028-a1cb74d2-e930-403b-bc6d-9a0e2ab04d0b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "#Since the RandomForestClassifier has the lower RMSE and higher accuracy. \n#I choose RandomForestClassifier as my final model.\ny_predf = pipe2.predict(X_test)\nf1 = f1_score(y_test, y_predf)\nrmse_final = sqrt(mean_squared_error(y_test, y_predf))",
      "metadata": {
        "tags": [],
        "cell_id": "00028-657a4821-9412-4468-b946-7a0a9f25e410",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ab7a296",
        "execution_start": 1615515212058,
        "execution_millis": 10,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": "print(f'Final model F1 score - {f1}')",
      "metadata": {
        "tags": [],
        "cell_id": "00029-c02c6262-82ad-40db-abcb-3f60b7b127b6",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "8372ed3d",
        "execution_millis": 16,
        "execution_start": 1615515477940,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Final model F1 score - 0.8674698795180722\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 68
    },
    {
      "cell_type": "code",
      "source": "print(f'Final model RMSE - {rmse_final}')",
      "metadata": {
        "tags": [],
        "cell_id": "00031-820cefe6-5003-43ba-b494-c49a1667a864",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d71fcb5",
        "execution_start": 1615515492051,
        "execution_millis": 7,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Final model RMSE - 0.3804429551263411\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 69
    },
    {
      "cell_type": "markdown",
      "source": "__Conclusion__\n\nWe can see the F1 score looks pretty good, which means the final model can assist scientific specialists to make classification whether the patient has heart disease or not.\n\nThere are still some limitations on this analysis. First of all, the sample size is not large enough since it only contains about 300 observations. There are millions of people get heart disease in the world. It is unreasonable to do the analysis only based on 300 observations. Second, there could be other ways of variable selection instead of selecting all variables in the dataset.",
      "metadata": {
        "tags": [],
        "cell_id": "00032-4a204583-8621-40ea-b4a1-625c810bfe98",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00028-d742268e-8a4d-4c67-8738-d04921e2f6c4",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "__Appendix__\n\n- age\n- sex\n- cp: chest pain type (4 values)\n- trestbps: resting blood pressure\n- chol: serum cholestoral in mg/dl\n- fbs: fasting blood sugar > 120 mg/dl\n- restecg: resting electrocardiographic results (values 0,1,2)\n- thalach: maximum heart rate achieved\n- exang: exercise induced angina\n- oldpeak: ST depression induced by exercise relative to rest\n- slope: the slope of the peak exercise ST segment\n- ca: number of major vessels (0-3) colored by flourosopy\n- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect",
      "metadata": {
        "tags": [],
        "cell_id": "00017-64751115-86e5-4361-9103-158d057deaeb",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00019-3f10d8f4-bae2-4d0f-864f-4eb03085edde",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d97214c9-1065-4a57-8603-4c15196f2d7e' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "c3044a6b-5e2e-41a5-830e-842e0e84cd94",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}